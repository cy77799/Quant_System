"""
é•·ç·šé‡åŒ–ç³»çµ± - Part 1: æ•¸æ“šå±¤ + Universe ç¯©é¸
ä¿®æ­£ç‰ˆï¼ˆè™•ç† yfinance æ•¸æ“šçµæ§‹ï¼‰
"""

import yfinance as yf
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# ============================================
# 1) é…ç½®åƒæ•¸
# ============================================

CONFIG = {
    # Universe ç¯©é¸æ¨™æº–
    'min_market_cap': 2_000_000_000,  # $2B
    'min_avg_volume': 10_000_000,     # $10M
    'min_price': 5.0,                 # $5
    
    # è³ªé‡ç¯©é¸
    'min_roe': -50,                   # ROE ä¸‹é™ï¼ˆ%ï¼‰
    'max_debt_ratio': 500,            # è² å‚µæ¯”ä¸Šé™ï¼ˆ%ï¼‰
    'ipo_exclusion_months': 12,       # æ’é™¤ 12 å€‹æœˆå…§ IPO
    
    # æ•¸æ“šæœŸé–“
    'lookback_years': 10,             # å›æ¸¬ 10 å¹´
    'start_date': '2015-01-01',
    'end_date': '2025-12-31',
    
    # æ•¸æ“šè³ªé‡
    'max_missing_ratio': 0.10,        # æœ€å¤š 10% ç¼ºå¤±æ•¸æ“šï¼ˆæ”¾å¯¬ï¼‰
}

# ============================================
# 2) æ•¸æ“šä¸‹è¼‰æ¨¡çµ„
# ============================================

class DataDownloader:
    """ä¸‹è¼‰ä¸¦æ¸…ç†è‚¡ç¥¨æ•¸æ“š"""
    
    def __init__(self, config):
        self.config = config
        
    def get_sp500_tickers(self):
        """ç²å–è‚¡ç¥¨åˆ—è¡¨ï¼ˆå…§ç½®ä¸»è¦ç¾è‚¡ï¼‰"""
        print("ğŸ“¥ è¼‰å…¥è‚¡ç¥¨åˆ—è¡¨...")
        
        # 200+ éš»ä¸»è¦ç¾è‚¡ï¼ˆè·¨è¡Œæ¥­ï¼‰
        tickers = [
            # ç§‘æŠ€ (Technology)
            'AAPL', 'MSFT', 'NVDA', 'GOOGL', 'GOOG', 'META', 'AVGO', 'TSLA', 
            'ADBE', 'CRM', 'ORCL', 'ACN', 'CSCO', 'AMD', 'IBM', 'INTU', 
            'NOW', 'QCOM', 'TXN', 'AMAT', 'MU', 'ADI', 'LRCX', 'KLAC',
            'INTC', 'PYPL', 'ABNB', 'SNOW', 'PANW', 'CRWD', 'FTNT', 'NET',
            'TEAM', 'WDAY', 'DDOG', 'ZS', 'OKTA', 'SPLK', 'MRVL', 'SNPS',
            
            # é‡‘è (Financials)
            'BRK-B', 'JPM', 'V', 'MA', 'BAC', 'WFC', 'GS', 'MS', 'SPGI', 
            'AXP', 'BLK', 'C', 'SCHW', 'CB', 'MMC', 'PGR', 'AON', 'ICE',
            'CME', 'MCO', 'USB', 'TFC', 'PNC', 'COF', 'AIG', 'MET', 'PRU',
            'ALL', 'TRV', 'AFL', 'HIG', 'WTW', 'BRO', 'AJG', 'RJF',
            
            # é†«ç™‚ä¿å¥ (Healthcare)
            'UNH', 'JNJ', 'LLY', 'ABBV', 'MRK', 'TMO', 'ABT', 'DHR', 'PFE',
            'AMGN', 'ISRG', 'BMY', 'CVS', 'CI', 'ELV', 'GILD', 'VRTX', 'HUM',
            'ZTS', 'REGN', 'MRNA', 'IDXX', 'DXCM', 'BDX', 'BSX', 'SYK', 'MDT',
            'EW', 'RMD', 'ALGN', 'HOLX', 'A', 'BAX', 'ILMN', 'BIIB', 'IQV',
            
            # æ¶ˆè²»å“ (Consumer Discretionary & Staples)
            'AMZN', 'WMT', 'COST', 'HD', 'MCD', 'PG', 'KO', 'PEP', 'NKE',
            'SBUX', 'TGT', 'LOW', 'TJX', 'CMG', 'BKNG', 'MAR', 'DHI', 'YUM',
            'LULU', 'ROST', 'DG', 'DLTR', 'ULTA', 'BBY', 'ORLY', 'AZO',
            'CL', 'KMB', 'GIS', 'K', 'HSY', 'MKC', 'CHD', 'CLX', 'CAG',
            
            # å·¥æ¥­ (Industrials)
            'CAT', 'BA', 'UNP', 'HON', 'UPS', 'RTX', 'LMT', 'DE', 'GE',
            'MMM', 'GD', 'NOC', 'ETN', 'ITW', 'PH', 'EMR', 'FDX', 'NSC',
            'CSX', 'WM', 'RSG', 'CARR', 'OTIS', 'PCAR', 'IR', 'FAST',
            'ROK', 'DOV', 'XYL', 'VRSK', 'IEX', 'FTV', 'CPRT', 'ODFL',
            
            # èƒ½æº (Energy)
            'XOM', 'CVX', 'COP', 'SLB', 'EOG', 'MPC', 'PSX', 'VLO', 'OXY',
            'WMB', 'KMI', 'HAL', 'BKR', 'DVN', 'FANG', 'MRO', 'APA',
            'OKE', 'TRGP', 'LNG', 'EQT', 'CTRA', 'TPL', 'PR', 'CVE',
            
            # é€šè¨Šæœå‹™ (Communication Services)
            'NFLX', 'DIS', 'CMCSA', 'T', 'VZ', 'TMUS', 'CHTR', 'EA', 'TTWO',
            'NWSA', 'FOXA', 'OMC', 'LYV', 'MTCH', 'WBD',
            
            # å…¬ç”¨äº‹æ¥­ (Utilities)
            'NEE', 'DUK', 'SO', 'D', 'AEP', 'EXC', 'SRE', 'PEG', 'XEL',
            'ED', 'WEC', 'ES', 'AWK', 'DTE', 'PPL', 'FE', 'CMS', 'AEE',
            'ATO', 'CNP', 'NI', 'LNT', 'EVRG', 'PNW', 'NWE', 'OGE',
            
            # æˆ¿åœ°ç”¢ (Real Estate)
            'AMT', 'PLD', 'CCI', 'EQIX', 'PSA', 'WELL', 'SPG', 'O', 'DLR',
            'SBAC', 'VICI', 'AVB', 'EQR', 'INVH', 'MAA', 'ESS', 'VTR',
            'ARE', 'BXP', 'KIM', 'REG', 'UDR', 'CPT', 'HST', 'SLG',
            
            # ææ–™ (Materials)
            'LIN', 'APD', 'SHW', 'ECL', 'NEM', 'FCX', 'CTVA', 'DD', 'DOW',
            'NUE', 'VMC', 'MLM', 'PPG', 'ALB', 'BALL', 'AVY', 'CE', 'IP',
            'EMN', 'CF', 'FMC', 'MOS', 'IFF', 'LYB', 'SEE', 'WRK',
        ]
        
        print(f"âœ… ç²å– {len(tickers)} éš»è‚¡ç¥¨")
        return tickers
    
    def download_price_data(self, tickers):
        """ä¸‹è¼‰åƒ¹æ ¼æ•¸æ“š"""
        print(f"\nğŸ“¥ ä¸‹è¼‰åƒ¹æ ¼æ•¸æ“š ({self.config['start_date']} è‡³ {self.config['end_date']})...")
        print(f"   ä¸‹è¼‰ {len(tickers)} éš»è‚¡ç¥¨...")
        
        data = yf.download(
            tickers,
            start=self.config['start_date'],
            end=self.config['end_date'],
            group_by='ticker',
            auto_adjust=True,
            threads=True,
            progress=False
        )
        
        print(f"âœ… ä¸‹è¼‰å®Œæˆ")
        return data
    
    def download_fundamental_data(self, tickers):
        """ä¸‹è¼‰åŸºæœ¬é¢æ•¸æ“š"""
        print(f"\nğŸ“¥ ä¸‹è¼‰åŸºæœ¬é¢æ•¸æ“š...")
        
        fundamentals = []
        total = len(tickers)
        
        for i, ticker in enumerate(tickers):
            if (i + 1) % 20 == 0 or (i + 1) == total:
                print(f"   é€²åº¦: {i+1}/{total} ({(i+1)/total*100:.1f}%)")
            
            try:
                stock = yf.Ticker(ticker)
                info = stock.info
                
                fundamentals.append({
                    'ticker': ticker,
                    'market_cap': info.get('marketCap', np.nan),
                    'sector': info.get('sector', 'Unknown'),
                    'pe_ratio': info.get('trailingPE', np.nan),
                    'pb_ratio': info.get('priceToBook', np.nan),
                    'roe': info.get('returnOnEquity', np.nan) * 100 if info.get('returnOnEquity') else np.nan,
                    'debt_to_equity': info.get('debtToEquity', np.nan),
                    'avg_volume': info.get('averageVolume', np.nan),
                    'current_price': info.get('currentPrice', np.nan),
                    'ipo_date': info.get('firstTradeDateEpochUtc', None),
                })
            except Exception as e:
                fundamentals.append({
                    'ticker': ticker,
                    'market_cap': np.nan,
                    'sector': 'Unknown',
                    'pe_ratio': np.nan,
                    'pb_ratio': np.nan,
                    'roe': np.nan,
                    'debt_to_equity': np.nan,
                    'avg_volume': np.nan,
                    'current_price': np.nan,
                    'ipo_date': None,
                })
        
        df = pd.DataFrame(fundamentals)
        print(f"âœ… ä¸‹è¼‰å®Œæˆ")
        return df

# ============================================
# 3) Universe ç¯©é¸æ¨¡çµ„
# ============================================

class UniverseFilter:
    """å…©å±¤ç¯©é¸ï¼šæµå‹•æ€§ + è³ªé‡"""
    
    def __init__(self, config):
        self.config = config
        
    def apply_filters(self, fundamentals_df):
        """æ‡‰ç”¨æ‰€æœ‰ç¯©é¸æ¢ä»¶"""
        print(f"\nğŸ” é–‹å§‹ Universe ç¯©é¸...")
        print(f"   åˆå§‹è‚¡ç¥¨æ•¸é‡: {len(fundamentals_df)}")
        
        df = fundamentals_df.copy()
        
        # ç¬¬ä¸€å±¤ï¼šæµå‹•æ€§ç¯©é¸
        df = self._filter_liquidity(df)
        
        # ç¬¬äºŒå±¤ï¼šè³ªé‡ç¯©é¸
        df = self._filter_quality(df)
        
        print(f"âœ… ç¯©é¸å®Œæˆï¼Œå‰©é¤˜ {len(df)} éš»è‚¡ç¥¨\n")
        
        return df
    
    def _filter_liquidity(self, df):
        """ç¬¬ä¸€å±¤ï¼šæµå‹•æ€§ç¯©é¸"""
        print("\nğŸ“Œ ç¬¬ä¸€å±¤ç¯©é¸ï¼ˆæµå‹•æ€§ï¼‰")
        
        initial_count = len(df)
        
        # 1. å¸‚å€¼ç¯©é¸
        df = df[df['market_cap'] >= self.config['min_market_cap']]
        print(f"   å¸‚å€¼ â‰¥ ${self.config['min_market_cap']:,.0f}: {len(df)} éš» (æ’é™¤ {initial_count - len(df)})")
        
        # 2. æˆäº¤é‡ç¯©é¸
        initial_count = len(df)
        df = df[df['avg_volume'] >= self.config['min_avg_volume']]
        print(f"   æ—¥å‡æˆäº¤é‡ â‰¥ {self.config['min_avg_volume']:,.0f}: {len(df)} éš» (æ’é™¤ {initial_count - len(df)})")
        
        # 3. è‚¡åƒ¹ç¯©é¸
        initial_count = len(df)
        df = df[df['current_price'] >= self.config['min_price']]
        print(f"   è‚¡åƒ¹ â‰¥ ${self.config['min_price']}: {len(df)} éš» (æ’é™¤ {initial_count - len(df)})")
        
        return df
    
    def _filter_quality(self, df):
        """ç¬¬äºŒå±¤ï¼šè³ªé‡ç¯©é¸"""
        print("\nğŸ“Œ ç¬¬äºŒå±¤ç¯©é¸ï¼ˆè³ªé‡ï¼‰")
        
        # 1. ROE ç¯©é¸
        initial_count = len(df)
        df = df[df['roe'] >= self.config['min_roe']]
        print(f"   ROE â‰¥ {self.config['min_roe']}%: {len(df)} éš» (æ’é™¤ {initial_count - len(df)})")
        
        # 2. è² å‚µæ¯”ç¯©é¸
        initial_count = len(df)
        df = df[df['debt_to_equity'] <= self.config['max_debt_ratio']]
        print(f"   è² å‚µæ¯” â‰¤ {self.config['max_debt_ratio']}%: {len(df)} éš» (æ’é™¤ {initial_count - len(df)})")
        
        # 3. IPO æ—¥æœŸç¯©é¸
        initial_count = len(df)
        cutoff_date = datetime.now() - timedelta(days=self.config['ipo_exclusion_months'] * 30)
        df = df[
            (df['ipo_date'].isna()) | 
            (pd.to_datetime(df['ipo_date'], unit='s') < cutoff_date)
        ]
        print(f"   æ’é™¤ {self.config['ipo_exclusion_months']} å€‹æœˆå…§ IPO: {len(df)} éš» (æ’é™¤ {initial_count - len(df)})")
        
        return df

# ============================================
# 4) æ•¸æ“šæ¸…ç†æ¨¡çµ„ï¼ˆä¿®æ­£ç‰ˆï¼‰
# ============================================

# ============================================
# 4) æ•¸æ“šæ¸…ç†æ¨¡çµ„ï¼ˆèª¿è©¦ç‰ˆï¼‰
# ============================================

class DataCleaner:
    """æ¸…ç†ä¸¦é©—è­‰æ•¸æ“šè³ªé‡"""
    
    def __init__(self, config):
        self.config = config
    
    def clean_price_data(self, price_data, universe_tickers):
        """æ¸…ç†åƒ¹æ ¼æ•¸æ“š"""
        print(f"\nğŸ§¹ æ¸…ç†åƒ¹æ ¼æ•¸æ“š...")
        print(f"   æ•¸æ“šçµæ§‹é¡å‹: {type(price_data)}")
        print(f"   Columns é¡å‹: {type(price_data.columns)}")
        
        # èª¿è©¦ï¼šæª¢æŸ¥æ•¸æ“šçµæ§‹
        if isinstance(price_data.columns, pd.MultiIndex):
            print(f"   MultiIndex å±¤ç´š: {price_data.columns.nlevels}")
            print(f"   å‰ 5 å€‹ columns: {list(price_data.columns[:5])}")
        else:
            print(f"   Columns: {list(price_data.columns)}")
        
        cleaned_data = {}
        total = len(universe_tickers)
        error_log = []
        
        for i, ticker in enumerate(universe_tickers):
            if (i + 1) % 10 == 0 or (i + 1) == total:
                print(f"   é€²åº¦: {i+1}/{total} ({(i+1)/total*100:.1f}%) - æˆåŠŸ: {len(cleaned_data)}")
            
            try:
                # è™•ç† yfinance æ•¸æ“šçµæ§‹
                if isinstance(price_data.columns, pd.MultiIndex):
                    # å¤šè‚¡ç¥¨ä¸‹è¼‰ï¼šcolumns = MultiIndex
                    # æª¢æŸ¥ ticker æ˜¯å¦å­˜åœ¨
                    available_tickers = price_data.columns.get_level_values(0).unique()
                    
                    if ticker not in available_tickers:
                        error_log.append(f"{ticker}: ä¸åœ¨ä¸‹è¼‰æ•¸æ“šä¸­")
                        continue
                    
                    df = price_data[ticker].copy()
                else:
                    # å–®è‚¡ç¥¨ä¸‹è¼‰
                    df = price_data.copy()
                
                # ç¢ºä¿æœ‰ Close åˆ—
                if 'Close' not in df.columns:
                    error_log.append(f"{ticker}: ç¼ºå°‘ Close åˆ—")
                    continue
                
                # ç§»é™¤å…¨ NaN çš„è¡Œ
                df = df.dropna(how='all')
                
                # æª¢æŸ¥æ•¸æ“šå®Œæ•´æ€§
                close_series = df['Close'].dropna()
                
                if len(close_series) == 0:
                    error_log.append(f"{ticker}: Close åˆ—å…¨ç‚º NaN")
                    continue
                
                missing_ratio = (len(df) - len(close_series)) / len(df)
                
                if missing_ratio > self.config['max_missing_ratio']:
                    error_log.append(f"{ticker}: ç¼ºå¤±æ•¸æ“šéå¤š ({missing_ratio:.1%})")
                    continue
                
                # å¡«å……ç¼ºå¤±å€¼ï¼ˆä½¿ç”¨æ–°èªæ³•ï¼‰
                df = df.ffill().bfill()
                
                # ç§»é™¤ç•°å¸¸å€¼ï¼ˆå–®æ—¥è®ŠåŒ– > 50%ï¼‰
                returns = df['Close'].pct_change()
                mask = abs(returns) < 0.50
                df = df[mask]
                
                # ç¢ºä¿è‡³å°‘æœ‰ 252 å€‹äº¤æ˜“æ—¥ï¼ˆ1å¹´ï¼‰
                if len(df) < 252:
                    error_log.append(f"{ticker}: æ•¸æ“šä¸è¶³ ({len(df)} å¤©)")
                    continue
                
                cleaned_data[ticker] = df
                
            except Exception as e:
                error_log.append(f"{ticker}: {str(e)}")
                continue
        
        print(f"\nâœ… æ¸…ç†å®Œæˆï¼Œå‰©é¤˜ {len(cleaned_data)} éš»è‚¡ç¥¨")
        
        # é¡¯ç¤ºå‰ 10 å€‹éŒ¯èª¤
        if len(error_log) > 0:
            print(f"\nâš ï¸  å‰ 10 å€‹å¤±æ•—åŸå› :")
            for err in error_log[:10]:
                print(f"   {err}")
        
        return cleaned_data


# ============================================
# 5) ä¸»æµç¨‹
# ============================================

def main():
    """ä¸»åŸ·è¡Œæµç¨‹"""
    
    print("=" * 60)
    print("ğŸš€ é•·ç·šé‡åŒ–ç³»çµ± - Part 1: æ•¸æ“š + Universe ç¯©é¸")
    print("=" * 60)
    
    # åˆå§‹åŒ–æ¨¡çµ„
    downloader = DataDownloader(CONFIG)
    universe_filter = UniverseFilter(CONFIG)
    cleaner = DataCleaner(CONFIG)
    
    # Step 1: ç²å–è‚¡ç¥¨åˆ—è¡¨
    tickers = downloader.get_sp500_tickers()
    
    # Step 2: ä¸‹è¼‰åŸºæœ¬é¢æ•¸æ“š
    fundamentals = downloader.download_fundamental_data(tickers)
    
    # Step 3: Universe ç¯©é¸
    filtered_universe = universe_filter.apply_filters(fundamentals)
    
    # Step 4: ä¸‹è¼‰ç¯©é¸å¾Œçš„åƒ¹æ ¼æ•¸æ“š
    universe_tickers = filtered_universe['ticker'].tolist()
    
    if len(universe_tickers) == 0:
        print("âŒ æ²’æœ‰è‚¡ç¥¨é€šéç¯©é¸ï¼Œè«‹æª¢æŸ¥ç¯©é¸æ¢ä»¶")
        return None, None
    
    price_data = downloader.download_price_data(universe_tickers)
    
    # Step 5: æ¸…ç†åƒ¹æ ¼æ•¸æ“š
    cleaned_prices = cleaner.clean_price_data(price_data, universe_tickers)
    
    # Step 6: æ›´æ–° universeï¼ˆåªä¿ç•™æœ‰å®Œæ•´æ•¸æ“šçš„è‚¡ç¥¨ï¼‰
    final_tickers = list(cleaned_prices.keys())
    filtered_universe = filtered_universe[filtered_universe['ticker'].isin(final_tickers)]
    
    # Step 7: è¼¸å‡ºçµæœ
    print("\n" + "=" * 60)
    print("ğŸ“Š æœ€çµ‚ Universe çµ±è¨ˆ")
    print("=" * 60)
    print(f"è‚¡ç¥¨æ•¸é‡: {len(cleaned_prices)}")
    
    if len(cleaned_prices) > 0:
        print(f"\nè¡Œæ¥­åˆ†ä½ˆ:")
        sector_dist = filtered_universe['sector'].value_counts()
        for sector, count in sector_dist.items():
            print(f"   {sector}: {count}")
        
        # ä¿å­˜çµæœ
        filtered_universe.to_csv('universe.csv', index=False)
        print("\nâœ… Universe å·²ä¿å­˜è‡³ universe.csv")
    else:
        print("\nâŒ ç„¡æœ‰æ•ˆæ•¸æ“š")
    
    return filtered_universe, cleaned_prices

if __name__ == "__main__":
    universe, prices = main()
